{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the following packages before running the code:\n",
    "1/ cv2\n",
    "2/ tqdm\n",
    "3/ densratio\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import cv2 # using opencv to process image\n",
    "from tqdm import tqdm  # use tqdm to know the process of the iteration\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os         \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from densratio import densratio\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "train_path = r'C:\\Users\\phuph\\Desktop\\Spiderdatabase\\spidertrainset'\n",
    "csv_path = r'C:\\Users\\phuph\\Desktop\\Spiderdatabase\\spider_csv.csv'\n",
    "#test_path = 'test'\n",
    "\n",
    "size_img = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" From the image, record the label either dangerous or non\"\"\"\n",
    "def record_label(image_name):\n",
    "    label = image_name.split('.')[0]\n",
    "    if label == 'dangerous':\n",
    "        return 1\n",
    "    elif label == 'non':\n",
    "        return 0\n",
    "\n",
    "def create_train():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(train_path)):\n",
    "        path = os.path.join(train_path, img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_COLOR).astype(float)\n",
    "        img_data = cv2.resize(img_data, (size_img, size_img))\n",
    "        training_data.append([img_data, record_label(img) ])\n",
    "    #np.save('train_data.npy', training_data)\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1005/1005 [00:29<00:00, 26.77it/s]\n"
     ]
    }
   ],
   "source": [
    "train = create_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_train = []\n",
    "for i in train:\n",
    "    a = i[0].reshape(-1)\n",
    "    A_train.append(a)\n",
    "A_train = np.asarray(A_train)\n",
    "B_train = np.asarray([i[1] for i in train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phuph\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(A_train.shape[0])\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train0, X_test0, Y_train, Y_test,idx1,idx2 = train_test_split(A_train, B_train,indices, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train1 = scaler.fit_transform(X_train0)\n",
    "X_test1 = scaler.fit_transform(X_test0)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_train = pca.fit_transform(X_train1)\n",
    "X_test= pca.transform(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nY_new_list = []\\nfor i in range(5):\\n    rho_po = random.choice(rho_po_list)\\n    rho_ne = random.choice(rho_ne_list)\\n    Y_temp = Y_train * (np.cumsum(Y_train) <= (1 - rho_po) * sum(Y_train))\\n    s = 1 - (1 - Y_train) * (np.cumsum(1 - Y_train) <= (1 - rho_ne) * sum(1 - Y_train))\\n    Y_temp[Y_train==0] = s[Y_train==0]\\n    Y_new_list.append([Y_temp,rho_po,rho_ne])\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "rho_po_list = [0.1,0.2,0.3,0.4,0.4]\n",
    "rho_ne_list = [0.3,0.1,0.4,0.1,0.4]\n",
    "Y_new_list = []\n",
    "for i in range(5):\n",
    "    rho_po = rho_po_list[i]\n",
    "    rho_ne = rho_ne_list[i]\n",
    "    Y_temp = np.copy(Y_train)\n",
    "    for j in range(len(Y_temp)):\n",
    "        if Y_train[j] ==1:\n",
    "            temp = random.random()\n",
    "            if temp < rho_po:\n",
    "                Y_temp[j] = 0\n",
    "        else:\n",
    "            t = random.random()\n",
    "            if t < rho_ne:\n",
    "                Y_temp[j] = 1\n",
    "    Y_new_list.append([Y_temp,rho_po,rho_ne])\n",
    "'''\n",
    "Y_new_list = []\n",
    "for i in range(5):\n",
    "    rho_po = random.choice(rho_po_list)\n",
    "    rho_ne = random.choice(rho_ne_list)\n",
    "    Y_temp = Y_train * (np.cumsum(Y_train) <= (1 - rho_po) * sum(Y_train))\n",
    "    s = 1 - (1 - Y_train) * (np.cumsum(1 - Y_train) <= (1 - rho_ne) * sum(1 - Y_train))\n",
    "    Y_temp[Y_train==0] = s[Y_train==0]\n",
    "    Y_new_list.append([Y_temp,rho_po,rho_ne])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "r = robjects.r\n",
    "#from rpy2.robjects.packages import importr\n",
    "#utils = importr(\"densratio\")\n",
    "import rpy2.robjects.numpy2ri as numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "robjects.r('''\n",
    "           f <- function(t,t1) {\n",
    "\n",
    "                    library(densratio)\n",
    "                    dens <- densratio(x = t, y = t1, method = \"KLIEP\")\n",
    "                    result <-dens$compute_density_ratio(t1)\n",
    "            }\n",
    "            ''')\n",
    "kliep_check = robjects.globalenv['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Estimate the noise rate###\n",
    "def KLIEP_e(X,Y):\n",
    "    e_list=[]\n",
    "    X_rho_po= X[Y ==1]\n",
    "    X_rho_ne= X[Y ==0]\n",
    "    result_po= kliep_check(X_rho_po,X)\n",
    "    result_ne= kliep_check(X_rho_ne,X)\n",
    "    Po = np.asarray(result_po)\n",
    "    Ne = np.asarray(result_ne)\n",
    "    n = len(X)\n",
    "    py_po = sum(1 for i in Y if i==1)/n\n",
    "    py_ne = sum(1 for i in Y if i==0)/n\n",
    "    Po_n = min(Po*py_po)\n",
    "    Ne_n = min(Ne*py_ne)\n",
    "    e_list.append([Ne_n,Po_n])\n",
    "    return e_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 0.3 [[0.2596719578146986, 0.33533738638873317]]\n",
      "1 0.2 0.1 [[0.38371144928449974, 0.22134167674421007]]\n",
      "2 0.3 0.4 [[0.30488436530293855, 0.3082745739294161]]\n",
      "3 0.4 0.1 [[0.50103661922822973, 0.13669309829085971]]\n",
      "4 0.4 0.4 [[0.40422633995262341, 0.30335501021150235]]\n"
     ]
    }
   ],
   "source": [
    "### Estimate the noise rate###\n",
    "count =0\n",
    "for i in Y_new_list:\n",
    "    a = KLIEP_e(X_train,i[0])\n",
    "    print(count,i[1],i[2],a)\n",
    "    count = count +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KLIEP_betas(X,Y):\n",
    "    e_list=[]\n",
    "    X_rho_po= X[Y ==1]\n",
    "    X_rho_ne= X[Y ==0]\n",
    "    result_po= kliep_check(X_rho_po,X)\n",
    "    result_ne= kliep_check(X_rho_ne,X)\n",
    "    Po = np.asarray(result_po)\n",
    "    Ne = np.asarray(result_ne)\n",
    "    n = len(X)\n",
    "    py_po = sum(1 for i in Y if i==1)/n\n",
    "    py_ne = sum(1 for i in Y if i==0)/n\n",
    "    Po_n = min(Po*py_po)\n",
    "    Ne_n = min(Ne*py_ne)\n",
    "    betas = np.ones((n,), dtype = None)\n",
    "    for i in range(n):\n",
    "        if Y[i] == 0:\n",
    "            if Po[i] == 0:\n",
    "                betas[i] = 0\n",
    "            else:\n",
    "                betas[i] = (Po[i]*py_po - Po_n)/ ((1-Po_n-Ne_n)*Po[i]*py_po)\n",
    "        else: \n",
    "            if Ne[i] == 0:\n",
    "                betas[i] =0\n",
    "            else:\n",
    "                betas[i] = (Ne[i]*py_ne - Ne_n)/ ((1-Po_n-Ne_n)*Ne[i]*py_ne)\n",
    "\n",
    "    return betas    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dims = X_train.shape[1]\n",
    "n_y = 2\n",
    "print( 'Number of features: %d ' %dims)\n",
    "print( 'Number of classes: %d' %n_y)\n",
    "print(\"Building model...\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_shape=(dims,)))\n",
    "model.add(Dense(60, input_shape=(dims,)))\n",
    "model.add(Dense(40, input_shape=(dims,)))\n",
    "model.add(Dense(n_y, input_shape=(dims,)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',sample_weight_mode=None,metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Accuracy for baseline flipped dataset - noisy#\n",
    "accuracy_list =[]\n",
    "count =0\n",
    "for i in Y_new_list:\n",
    "    y= np_utils.to_categorical(i[0], 2)\n",
    "    model.fit(X_train,y, verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([count,a,i[1],i[2]])\n",
    "    count = count +1\n",
    "for i in accuracy_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Accuracy for auto without RANDOM-using KLIEP to estimate noise ###\n",
    "accuracy_list =[]\n",
    "for i in Y_new_list:\n",
    "    rho_po_max = i[1]\n",
    "    rho_ne_max = i[2]\n",
    "    X_rho_po= X_train[i[0] ==1]\n",
    "    result_po= kliep_check(X_rho_po,X_train)\n",
    "    Po = np.asarray(result_po)\n",
    "    n = len(X_train)\n",
    "    py_po = sum(1 for z in i[0]  if z==1)/n\n",
    "    eta_po = Po*py_po\n",
    "\n",
    "    St = []\n",
    "    distill_ind = []\n",
    "    for t in range(n):\n",
    "        if eta_po[t] > ((1+rho_ne_max)/2):\n",
    "            St.append([X_train[t],1])\n",
    "            distill_ind.append([idx1[t],1])\n",
    "\n",
    "        elif eta_po [t]  < ((1-rho_po_max)/2):\n",
    "            St.append([X_train[t],0])\n",
    "            distill_ind.append([idx1[t],0])\n",
    "    St.append([X_train[1],1])\n",
    "    St.append([X_train[1],0])\n",
    "    St_x =np.asarray([i[0] for i in St])\n",
    "    St_y =np.asarray([i[1] for i in St])\n",
    "    print(St_y)\n",
    "    count =0\n",
    "    y= np_utils.to_categorical(St_y, 2)\n",
    "    model.fit(St_x,y, verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([count,a,i[1],i[2]])\n",
    "    count = count +1\n",
    "    \n",
    "for i in accuracy_list:\n",
    "    print(i)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy - auto without random with LR estimate##\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "accuracy_list =[]\n",
    "for i in Y_new_list:\n",
    "    r = [0.1, 0.2, 0.3, 0.4]\n",
    "    rho_po_max = i[1]\n",
    "    rho_ne_max = i[2]\n",
    "    n = len(X_train)\n",
    "    clf.fit(X_train,i[0])\n",
    "    e = clf.predict_proba(X_train)\n",
    "    eta_po = np.asarray([i[1] for i in e])\n",
    "    St = []\n",
    "    St_n=[]\n",
    "    distill_ind = []\n",
    "\n",
    "    for t in range(n):\n",
    "        if eta_po[t] > ((1+rho_ne_max)/2):\n",
    "            St.append([X_train[t],1])\n",
    "            distill_ind.append([idx1[t],1])\n",
    "\n",
    "        elif eta_po [t]  < ((1-rho_po_max)/2):\n",
    "            St.append([X_train[t],0])\n",
    "            distill_ind.append([idx1[t],0])\n",
    "        else: \n",
    "            St_n.append([X_train[t],Y_train[t]])\n",
    "    \n",
    "      \n",
    "    St_x =np.asarray([i[0] for i in St])\n",
    "    St_y =np.asarray([i[1] for i in St])\n",
    "    \n",
    "    print(St_y)\n",
    "    \n",
    "    count =0\n",
    "    sample_weight = KLIEP_betas(St_x,St_y)\n",
    "    y= np_utils.to_categorical(St_y, 2)\n",
    "    model.fit(St_x,y,sample_weight=sample_weight,verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([count,a,rho_po_max,rho_ne_max])\n",
    "    count = count +1\n",
    "    \n",
    "for i in accuracy_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Accuracy for auto WITH RANDOM - using LR to estimate noise ###\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "accuracy_list =[]\n",
    "for i in Y_new_list:\n",
    "    r = [0.1, 0.2, 0.3, 0.4]\n",
    "    rho_po_max = i[1]\n",
    "    rho_ne_max = i[2]\n",
    "    n = len(X_train)\n",
    "    clf.fit(X_train,i[0])\n",
    "    e = clf.predict_proba(X_train)\n",
    "    eta_po = np.asarray([i[1] for i in e])\n",
    "    St = []\n",
    "    St_n=[]\n",
    "    distill_ind = []\n",
    "\n",
    "    for t in range(n):\n",
    "        if eta_po[t] > ((1+rho_ne_max)/2):\n",
    "            St.append([X_train[t],1])\n",
    "            distill_ind.append([idx1[t],1])\n",
    "\n",
    "        elif eta_po [t]  < ((1-rho_po_max)/2):\n",
    "            St.append([X_train[t],0])\n",
    "            distill_ind.append([idx1[t],0])\n",
    "        else: \n",
    "            St_n.append([X_train[t],Y_train[t]])\n",
    "    \n",
    "    q = 0\n",
    "    while (q<20):\n",
    "        z = random.randint(0,len(St_n))\n",
    "        St.append(St_n[z])\n",
    "        q = q+1\n",
    "    \n",
    "      \n",
    "    St_x =np.asarray([i[0] for i in St])\n",
    "    St_y =np.asarray([i[1] for i in St])\n",
    "    \n",
    "    print(St_y)\n",
    "    \n",
    "    count =0\n",
    "    sample_weight = KLIEP_betas(St_x,St_y)\n",
    "    y= np_utils.to_categorical(St_y, 2)\n",
    "    model.fit(St_x,y,sample_weight=sample_weight,verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([count,a,rho_po_max,rho_ne_max])\n",
    "    count = count +1\n",
    "    \n",
    "for i in accuracy_list:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Accuracy Rater Label using KLIEP\"\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "accuracy_list =[]\n",
    "df_noise = pd.read_csv(csv_path)\n",
    "C_train = np.asarray(df_noise[\"Rater label\"])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index,test_index in skf.split(A_train,C_train,B_train):\n",
    "    X_train0, X_test0 = A_train[train_index], A_train[test_index]\n",
    "    Y_train, Y_test = C_train[train_index], C_train[test_index]\n",
    "    BB_train, BB_test = B_train[train_index], B_train[test_index]\n",
    "    idx1= train_index\n",
    "    X_train1 = scaler.fit_transform(X_train0)\n",
    "    X_test1 = scaler.fit_transform(X_test0)\n",
    "\n",
    "    X_train = pca.fit_transform(X_train1)\n",
    "    X_test= pca.transform(X_test1)\n",
    "\n",
    "    r = [0.1,0.15, 0.2, 0.25, 0.3,0.35, 0.4, 0.45]\n",
    "    #rho_po_max = 0.2\n",
    "    #rho_ne_max = 0.45\n",
    "    rho_po_max = random.choice(rho_po_list)\n",
    "    rho_ne_max = random.choice(rho_ne_list)\n",
    "    X_rho_po= X_train[Y_train ==1]\n",
    "    result_po= kliep_check(X_rho_po,X_train)\n",
    "    Po = np.asarray(result_po)\n",
    "    n = len(X_train)\n",
    "    py_po = sum(1 for z in Y_train if z==1)/n\n",
    "    eta_po = Po*py_po\n",
    "\n",
    "    St = []\n",
    "    St_n=[]\n",
    "    distill_ind = []\n",
    "\n",
    "    for t in range(n):\n",
    "        if eta_po[t] > ((1+rho_ne_max)/2):\n",
    "            St.append([X_train[t],1])\n",
    "            distill_ind.append([idx1[t],1])\n",
    "\n",
    "        elif eta_po [t]  < ((1-rho_po_max)/2):\n",
    "            St.append([X_train[t],0])\n",
    "            distill_ind.append([idx1[t],0])\n",
    "        else: \n",
    "            St_n.append([X_train[t],BB_train[t]])\n",
    "\n",
    "\n",
    "    q = 0\n",
    "    while (q<20):\n",
    "        z = random.randint(0,len(St_n))\n",
    "        St.append(St_n[z])\n",
    "        q = q+1\n",
    "\n",
    "    St_x =np.asarray([t[0] for t in St])\n",
    "    St_y =np.asarray([t[1] for t in St])\n",
    "    print(St_y)\n",
    "    sample_weight = KLIEP_betas(St_x,St_y)\n",
    "    y= np_utils.to_categorical(St_y, 2)\n",
    "    model.fit(St_x,y,sample_weight=sample_weight,verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([a])\n",
    "\n",
    "print(np.mean(accuracy_list,axis=0),np.std(accuracy_list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Accuracy on spiderdataset with instance class dependent using LR ##3\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "accuracy_list =[]\n",
    "df_noise = pd.read_csv(csv_path)\n",
    "C_train = np.asarray(df_noise[\"Rater label\"])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index,test_index in skf.split(A_train,C_train,B_train):\n",
    "    X_train0, X_test0 = A_train[train_index], A_train[test_index]\n",
    "    Y_train, Y_test = C_train[train_index], C_train[test_index]\n",
    "    BB_train, BB_test = B_train[train_index], B_train[test_index]\n",
    "    idx1= train_index\n",
    "    X_train1 = scaler.fit_transform(X_train0)\n",
    "    X_test1 = scaler.fit_transform(X_test0)\n",
    "\n",
    "    X_train = pca.fit_transform(X_train1)\n",
    "    X_test= pca.transform(X_test1)\n",
    "\n",
    "    r = [0.1,0.15, 0.2, 0.25, 0.3,0.35, 0.4, 0.45]\n",
    "    #rho_po_max = 0.2\n",
    "    #rho_ne_max = 0.45\n",
    "    rho_po_max = random.choice(rho_po_list)\n",
    "    rho_ne_max = random.choice(rho_ne_list)\n",
    "    n = len(X_train)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    e = clf.predict_proba(X_train)\n",
    "    eta_po = np.asarray([i[1] for i in e])\n",
    "    \n",
    "    St = []\n",
    "    St_n=[]\n",
    "    distill_ind = []\n",
    "\n",
    "    for t in range(n):\n",
    "        if eta_po[t] > ((1+rho_ne_max)/2):\n",
    "            St.append([X_train[t],1])\n",
    "            distill_ind.append([idx1[t],1])\n",
    "\n",
    "        elif eta_po [t]  < ((1-rho_po_max)/2):\n",
    "            St.append([X_train[t],0])\n",
    "            distill_ind.append([idx1[t],0])\n",
    "        else: \n",
    "            St_n.append([X_train[t],BB_train[t]])\n",
    "\n",
    "\n",
    "    q = 0\n",
    "    while (q<20):\n",
    "        z = random.randint(0,len(St_n))\n",
    "        St.append(St_n[z])\n",
    "        q = q+1\n",
    "\n",
    "    St_x =np.asarray([t[0] for t in St])\n",
    "    St_y =np.asarray([t[1] for t in St])\n",
    "    print(St_y)\n",
    "    sample_weight = KLIEP_betas(St_x,St_y)\n",
    "    y= np_utils.to_categorical(St_y, 2)\n",
    "    model.fit(St_x,y,sample_weight=sample_weight,verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([a])\n",
    "\n",
    "print(np.mean(accuracy_list,axis=0),np.std(accuracy_list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### FOR AUTO USING ACTIVE LEARNING FOR FLIPPED DATASET  ###\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "accuracy_list =[]\n",
    "for i in Y_new_list:\n",
    "    r = [0.1, 0.2, 0.3, 0.4]\n",
    "    rho_po_max = i[1]\n",
    "    rho_ne_max = i[2]\n",
    "    n = len(X_train)\n",
    "     \n",
    "    clf.fit(X_train,i[0])\n",
    "    e = clf.predict_proba(X_train)\n",
    "    eta_po = np.asarray([i[1] for i in e])\n",
    "    d = clf.decision_function(X_train)\n",
    "\n",
    "    St = []\n",
    "    St_n=[]\n",
    "    St_d=[]\n",
    "    distill_ind = []\n",
    "\n",
    "    for t in range(n):\n",
    "        if eta_po[t] > ((1+rho_ne_max)/2):\n",
    "            St.append([X_train[t],1])\n",
    "            distill_ind.append([idx1[t],1])\n",
    "\n",
    "        elif eta_po [t]  < ((1-rho_po_max)/2):\n",
    "            St.append([X_train[t],0])\n",
    "            distill_ind.append([idx1[t],0])\n",
    "        else: \n",
    "            St_n.append([X_train[t],Y_train[t]])\n",
    "            St_d.append(d[t])\n",
    "    dist = np.abs(St_d)\n",
    "    a = dist.argsort()[:20]\n",
    "    for z in a:\n",
    "        St.append(St_n[z])\n",
    "    \n",
    "    St_x =np.asarray([i[0] for i in St])\n",
    "    St_y =np.asarray([i[1] for i in St])\n",
    "    \n",
    "    print(St_y)\n",
    "    count =0\n",
    "    sample_weight = KLIEP_betas(St_x,St_y)\n",
    "    y= np_utils.to_categorical(St_y, 2)\n",
    "    model.fit(St_x,y,sample_weight=sample_weight,verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([count,a,rho_po_max,rho_ne_max])\n",
    "    count = count +1\n",
    "    \n",
    "for i in accuracy_list:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "accuracy_list =[]\n",
    "df_noise = pd.read_csv(csv_path)\n",
    "C_train = np.asarray(df_noise[\"Rater label\"])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index,test_index in skf.split(A_train,C_train, B_train):\n",
    "    X_train0, X_test0 = A_train[train_index], A_train[test_index]\n",
    "    Y_train, Y_test = C_train[train_index], C_train[test_index]\n",
    "    BB_train, BB_test = B_train[train_index], B_train[test_index]\n",
    "    idx1= train_index\n",
    "    X_train1 = scaler.fit_transform(X_train0)\n",
    "    X_test1 = scaler.fit_transform(X_test0)\n",
    "\n",
    "    X_train = pca.fit_transform(X_train1)\n",
    "    X_test= pca.transform(X_test1)\n",
    "\n",
    "    r = [0.1,0.15, 0.2, 0.25, 0.3,0.35, 0.4, 0.45]\n",
    "    rho_po_max = random.choice(rho_po_list)\n",
    "    rho_ne_max = random.choice(rho_ne_list)\n",
    "    n = len(X_train)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    e = clf.predict_proba(X_train)\n",
    "    eta_po = np.asarray([i[1] for i in e])\n",
    "    d = clf.decision_function(X_train)\n",
    "        \n",
    "    \n",
    "    St = []\n",
    "    St_n=[]\n",
    "    distill_ind = []\n",
    "    St_d=[]\n",
    "\n",
    "    for t in range(n):\n",
    "        if eta_po[t] > ((1+rho_ne_max)/2):\n",
    "            St.append([X_train[t],1])\n",
    "            distill_ind.append([idx1[t],1])\n",
    "\n",
    "        elif eta_po [t]  < ((1-rho_po_max)/2):\n",
    "            St.append([X_train[t],0])\n",
    "            distill_ind.append([idx1[t],0])\n",
    "        else: \n",
    "            St_n.append([X_train[t],BB_train[t]])\n",
    "            St_d.append(d[t])\n",
    "\n",
    "    dist = np.abs(St_d)\n",
    "    a = dist.argsort()[:20]\n",
    "    for z in a:\n",
    "        St.append(St_n[z])\n",
    "   \n",
    "\n",
    "    St_x =np.asarray([t[0] for t in St])\n",
    "    St_y =np.asarray([t[1] for t in St])\n",
    "    print(St_y)\n",
    "    sample_weight = KLIEP_betas(St_x,St_y)\n",
    "    y= np_utils.to_categorical(St_y, 2)\n",
    "    model.fit(St_x,y,sample_weight=sample_weight,verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([a])\n",
    "\n",
    "print(np.mean(accuracy_list,axis=0),np.std(accuracy_list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = ['steelblue' if label == 1 else 'darkred' for label in y]\n",
    "plt.scatter(X[:,0], X[:,1], color=colors)\n",
    "y.shape, X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
